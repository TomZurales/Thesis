\subsection{Motivation}

The inspiration for this research came from a project to utilize keypoint based visual SLAM on the Astrobee robots on the International Space Station (ISS). At the time of the project, Astrobee navigation was accomplished through localization on a pre-generated map, which required both astronaut and ground team intervention to produce \cite{soussanAstroLocEfficientRobust2022}. Due to the tight schedules and high costs associated with ISS astronaut work, this map creation happened very rarely.

The ISS is a challenging place to perform robot navigation tasks. The primary structure of the station remains the same, with nodes always connecting to the same nodes, but regular resupply, hardware replacement, temporary experimental setups, and general crew living can cause the station to gradually change from day to day. This high variation in the internal features of the space station caused the Astrobee maps to quickly go out of date, severely limiting the robot's autonomous capabilities and utilities as a research platform \cite{PLACEHOLDER}.

It was the intention of the project to run keypoint based visual SLAM on board the Astrobees, allowing them the capabilities to create and update their own maps and eliminating the need for astronaut intervention. In order to be useful for ISS operations, the SLAM algorithm had to output its map and localization estimates in the established ISS coordinate frame \cite{PLACEHOLDER}. To accomplish this, the decision was made early on to build off of a SLAM system which included the ability to load and merge previously generated maps. Assuming the system localizes in the pregenerated map, the coordinate frame can be preserved between mapping runs by merging the new data into the old map. This is where the non-static nature of the ISS produces problems for SLAM. If a map is generated a significant time before it is used, there is ample opportunity for the visual features of the environment to change, leading to poor performance when attempting to localize within this previously generated map. While out of scope for the previous project, the researchers noted that these out of date visual features in the previously generated map posed a challenge for SLAM operations in similarly dynamic environments.

\subsubsection{Problem Statement}

A primary assumption in SLAM is that the environment remains static\cite{PLACEHOLDER}

\subsubsection{Research Questions}

Does a probability model which identifies and culls outdated map points provide significant improvements to relocalization and tracking during map reuse in keypoint-based SLAM?
To what extent do dynamic changes in a map affect mapping and relocalization performance?
Can this be used as a heuristic to determine when to re-enable mapping on MAVs?

The spacial understanding provided by SLAM is not only useful, but necessary for systems intending to operate in and interact with physical environments. Virtual reality, robotics, and industrial automation all make use of SLAM to generate an internal map of the local and global environments. SLAM does have the distinction of being a "solved" problem in the ideal case. If an agent is able to perfectly measure the environment, and is guaranteed to make correct data associations, then a perfect map can be generated and the agent's location within that map can be known with certainty. This ideal case makes several assumptions, paramount of which is the existence of ideal sensors, but there is a secondary assumption that the state of the world does not change.

It is obvious that the assumption of a static, unchanging world does not hold in practice. In fact, the inspiration for this research came from attempts to perform localization on the International Space Station (ISS). As of the time of publication, there are three mobile autonomous vehicles (MAVs) on board the ISS known as Astrobees. While used for numerous experiments and product development tasks on the ISS, the Astrobees are prone to failure due to loss of localization. The primary cause of this localization failure is the constant changes occurring on the ISS, including equipment changes, resupply missions, and any other activities which may change the visual features of the ISS.

The situation on the ISS is not unique, and would be experienced by any agent running SLAM in all but the most tightly controlled environments. VR goggles using use SLAM to determine their position in 3D space within a room must contend with new objects which are placed in the room, the changing images shown on the TV, people walking in and out of view, etc. Robots operating in an office environment must be robust to moved desks, the movement of people, and more. Even robotic operations in an unmanned space station (a situation proposed for the Lunar Gateway project) would need to be able to perform despite changing lighting conditions, moved equipment, other MAVs in view, etc. Overall, a requirement that a SLAM agent gets to operate in a pristine, unchanging environment would be an insurmountable barrier for real world use.

The field of research into making SLAM perform over long timeframes has been called lifetime SLAM[], eluding to the fact that SLAM systems with the requirement for an unchanging environment will still be able to operate successfully over short timeframes, but will struggle with missions which take place over multiple days, weeks, months, or years.

This research is specific to a subset of the greater SLAM problem known as keypoint-based, visual SLAM. The distinctions between these will be discussed in detail in the Background section, but a high-level overview is offered here. Keypoint-based visual SLAM operates on images taken over time. The core principal involves constructing a sparse 3D map of image features which are identifiable from multiple perspectives. This is accomplished through photogrammetry methods such as the 5-point method, which allows the depths of 5 matched pairs of points, and the parallax transformation to be determined from two 2d images [FACT CHECK and CITATION].

<!-- Go into a few more details about some of the other fields of research which are used by SLAM -->

There are numerous keypoint-based visual SLAM implementations seeing use today, but all follow a relatively straightforward pipeline, defined as follows:

1. Determine an initial set of 3D points from two images with sufficient parallax
2. For subsequent images, match features with previously identified 3D points
3. Determine the transformation between the previous image and the new image which maximizes the number of map point alignments

Implementation differences tend to come from optimization steps, pruning of redundant data, anomaly handling, and additional sensor integrations. In order to achieve lifetime SLAM, the system must be able to determine what data is remaining static, what data is changing, and act accordingly. Imagine an art gallery with many paintings on the walls. If you were to visit this gallery on two separate occasions one year apart, the paintings on the walls may change, but you are able to identify that you are in the same gallery. People perform this contextual elimination of data which may change on a subconscious level []. Replicating this contextual awareness in SLAM allows systems to recognize and focus on unchanging data while ignoring dynamic data which could clutter and confuse the agent's internal map.

The benefits of eliminating data which is not helpful for long-term operations are plentiful. Just like culling redundant data, culling dynamic data reduces the overall size of the map. This reduces storage capacity requirements, while providing a smaller pool of data through which processes like Random Sample Consensus (RanSaC) need to search. A keypoint which was seen on an object which is later moved will always be an outlier in subsequent observations. Through culling of these dynamic data points, we can improve the speed and robustness of the several optimization steps, reduce overall system hardware requirements, and increase confidence in the accuracy and validity of the produced maps.

Numerous methods for improving SLAM's performance over long timeframes have been implemented, pushing the field of SLAM to the point where it is now seeing deployment in numerous dynamic environments. A discussion of several of these implementations takes place in the Background section, with a focus on each implementation's strengths, weaknesses, and overall effectiveness. An area that remains lacking is implementations on MAVs with limited compute. Due to their mobile nature, MAVs are inherently compute limited, as any additional weight and power consumption decreases capability and operation time. This prevents the inclusion of many popular models for dynamic data elimination such as image segmentation and semantic identification. Other methods utilizing statistical methods for point existence exist, but fail to fully utilize the vast array of data to update their predictions