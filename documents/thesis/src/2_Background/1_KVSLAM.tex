\subsection{Keypoint-Based Visual SLAM}

% What is SLAM? What are its goals? What are its use cases?
SLAM refers to the joint problem of simultaneously generating a map of an environment and estimating the position of an observer within that map based on sensor observations. With research beginning in the 1980s \cite{smithEstimatingUncertainSpatial1988}, SLAM has become a de facto standard in robotics for tasks which require operations within unfamiliar environments. Through careful selection of sensors, SLAM systems can operate in a wide variety of environments, from indoor office spaces to densely forested areas, and even underwater or in space. The benefit of SLAM when compared to other navigation methods such as pure localization is the ability to operate with no a-prioiri information, incrementally creating and updating the map, and the estimation of the observer's position within it. The selection of sensors is also extremely flexible, with many popular implementations existing for camera, LIDAR, and RGBD based sensor modalities. These features make SLAM a powerful too for autonomous navigation, leading to its widespread use in robotics, augmented reality, and autonomous vehicles.

% High level overview of the challenges of SLAM: computational complexity, sensor error accumulation, dynamic environments
However, there are challenges associated with SLAM. Despite numerous advancements, the computational complexity of performing SLAM in real-time remains a challenge, meaning that on many resource constrained platforms, implementations can struggle to keep up with the rate of sensor data acquisition \cite{semenovaQuantitativeAnalysisSystem2022}. Additionally, because there is no fixed reference, SLAM systems can suffer from sensor error accumulation, leading to inaccurate maps and poses over time \cite{cadenaPresentFutureSimultaneous2016}. These issues are compounded as the timeframe, scale, and environmental dynamics of the SLAM task increase. Larger environments require larger, more complex maps, which produce higher computational load and longer processing times. Dynamic environments, where objects can move or change either during the SLAM process or between runs, are a particular challenge, as most SLAM systems tend to operate best in static environments, and can struggle to maintain accurate pose estimation and map consistence in the presence of moving objects. The field of SLAM research known as \textit{lifelong SLAM} \cite{cadenaPresentFutureSimultaneous2016} focuses on addressing these challenges, and will be covered in detail in Section \ref{sec:related_work}.

% What are the defining characteristics of keypoint based visual SLAM as opposed to other SLAM methods?
This research targets Keypoint-Based Visual SLAM (KV-SLAM), a specific modality of SLAM characterized by its use of one or more cameras as the primary sensor, and the use of keypoints as opposed to raw pixel values as the primary data structure for constructing the map. Table \ref{tab:slam_sensor_modalities} provides a comparison of the strengths and weaknesses of the various sensor modalities used in SLAM. As can be seen, KV-SLAM is not the obvious choice, as it does not produce direct 3D measurements of the environment, instead relying on the estimation of 3D points from 2D observations. However, KV-SLAM has several advantages which make it an ideal choice for many applications. Cameras are inexpensive, widely available, and can provide rich information about the environment, opening the door to a semantic understanding of the environment.

\begin{table}[ht!]
    \centering
    \caption{Comparison of SLAM sensor modalities}
    \label{tab:slam_sensor_modalities}
\end{table}