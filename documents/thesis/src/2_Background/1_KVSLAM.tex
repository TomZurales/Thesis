\subsection{Keypoint-Based Visual SLAM}

% What is SLAM? What are its goals? What are its use cases?
SLAM refers to the joint problem of simultaneously generating a map of an environment and estimating the position of an observer within that map based on sensor observations. With research beginning in the 1980s \cite{smithEstimatingUncertainSpatial1988}, SLAM has become a de facto standard in robotics for tasks which require operations within unfamiliar environments. The benefit of SLAM when compared to other navigation methods such as pure localization is the ability to operate with no a-prioiri information, instead creating and incrementally updating the map at runtime. The selection of sensors is extremely flexible, with many popular implementations existing for camera, LIDAR, and RGBD based sensor modalities. Through careful selection of sensors, SLAM systems can operate in a wide variety of environments, from indoor office spaces to densely forested areas, and even underwater or in space.  These features make SLAM a powerful too for autonomous navigation, leading to its widespread use in robotics, augmented reality, and autonomous vehicles.

% What are the defining characteristics of keypoint based visual SLAM as opposed to other SLAM methods?
This research targets Keypoint-Based Visual SLAM (KV-SLAM), a specific modality of SLAM characterized by its use of one or more cameras as the primary sensor, and the use of keypoints as opposed to raw pixel values as the primary data for constructing the map and performing localization. As opposed to other sensor modalities such as LIDAR and RGBD, which take direct 3D measurements of the environment, KV-SLAM relies on the principles of epipolar geometry to infer depth and camera motion from the relative position of keypoints between image frames. The map generated by a KV-SLAM system is a sparse pointcloud of 3D map points. The process of transforming 

% High level overview of the challenges of SLAM: computational complexity, sensor error accumulation, dynamic environments
. Despite numerous advancements, the computational complexity of performing SLAM in real-time remains a challenge, meaning that on many resource constrained platforms, implementations can struggle to keep up with the rate of sensor data acquisition \cite{semenovaQuantitativeAnalysisSystem2022}. Additionally, because there is no fixed reference, SLAM systems can suffer from sensor error accumulation, leading to inaccurate maps and poses over time \cite{cadenaPresentFutureSimultaneous2016}. These issues are compounded as the timeframe, scale, and environmental dynamics of the SLAM task increase. Larger environments require larger, more complex maps, which produce higher computational load and longer processing times. Dynamic environments, where objects can move or change either during the SLAM process or between runs, are a particular challenge, as most SLAM systems tend to operate best in static environments, and can struggle to maintain accurate pose estimation and map consistence in the presence of moving objects. The field of SLAM research known as \textit{lifelong SLAM} \cite{cadenaPresentFutureSimultaneous2016} focuses on addressing these challenges, and will be covered in detail in Section \ref{sec:related_work}.
