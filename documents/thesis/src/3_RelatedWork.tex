\section{Related Work}
\label{sec:related_work}

This section contextualizes the proposed research within the larger body of SLAM research. At its core, this thesis falls under the umbrella of lifelong SLAM. Lifelong SLAM has varied definitions throughout the literature, but for simplicity, this research adopts the definition provided by Shi et al. \cite{shiAreWeReady2020}, describing lifelong SLAM as the ability for a robot to generate, maintain, and localize within a map of a particular environment over an extended period of time. This is in contradistinction to the standard SLAM operating model, which tends to require short timeframes due to the assumption of a static environment. Unlike standard SLAM, lifelong SLAM is expected to operate despite environmental changes such as moved objects, lighting changes, dynamic objects within sensor view, etc. This research falls under the topic of map maintenance, but has downstream effects on other operations related to lifelong SLAM.

\subsection{Place Recognition over Long Time Horizons}

As previously discussed, place recognition refers to the ability to determine when an agent has entered a previously visited area. In KV-SLAM, this is commonly achieved using a bag-of-words approach over binary feature discriptors extracted extracted from camera images \cite{camposORBSLAM3AccurateOpenSource2021}. However, these features can vary significantly over time due to changes in lighting, weather, scene layout, or viewpoint. Chen et al. \cite{chenDeepLearningFeatures2017} propose using deep-learning to identify features which are invariant to conditions and viewpoint, however they are still sensitive to geometric changes.

Milford et al. improved robustness to time-of-day and weather variation by matching sequences of whole-images comparisons rather than relying on a single image or feature-based matches. However, this approach requires alignment between the image sequence and the reference trajectory, effectively requiring similar speed and direction of travel. Naseer et al. \cite{naseerVisionbasedMarkovLocalization2015} relaxed this constraint by computing a full probability distribution over possible locations, relaxing the need for trajectory alignment. Both of these approches are sensitive to viewpoint variation, and can fail when the camera trajectory differs significantly from previously observed trajectories.

Learning-based methods like NetVLAD \cite{arandjelovicNetVLADCNNArchitecture2016} assign global descriptors to places rather than features, increasing robustness to viewpoint, conditions, and dynamic clutter. HF-Net \cite{sarlinCoarseFineRobust2019} extends this idea by utilizing global descriptors for large scale place recognition, and local learned features for refinement. The negative aspects of learning based approaches tends to be their computational load, requiring significantly higher capability than methods which do not require a neural network.

While the methods discussed here do allow for place recognition to succeed dispite significant visual and geometric changes, in general place recognition is most effective when the internal scene representation matches the true environment. To accomplish this, the system must be able to identify and correct discrepencies between the map and the current sensor readings.

\subsection{Change Detection for Map Maintenance}

Change detection in SLAM refers to identifying discrepencies between current sensor observations and the existing map. This functionality supports operations like relocalization and place recognition by acting as the mechanism through which outdated map data is identified so it can be updated.



\input{src/3_RelatedWork/1_LifeLongSLAM}
LÃ¡zaro et al.
